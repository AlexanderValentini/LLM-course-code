{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2ce73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from distilabel.models import InferenceEndpointsLLM, AsyncLLM\n",
    "from huggingface_hub import AsyncInferenceClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps import (\n",
    "    LoadDataFromHub,\n",
    "    GroupColumns,\n",
    "    FormatTextGenerationDPO,\n",
    "    PreferenceToArgilla,\n",
    ")\n",
    "from distilabel.steps.tasks import TextGeneration, UltraFeedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebfe252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file using python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv  # Import the library\n",
    "load_dotenv() \n",
    "hf_token = os.getenv(\"HF_TOKEN\") \n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in .env file or environment variables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5812b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since argilla/10Kprompts-mini couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\alix\\.cache\\huggingface\\datasets\\argilla___10_kprompts-mini\\default\\0.0.0\\cf99b34e5949c3e2310321438fb201cf27647d01 (last modified on Fri Jun 13 18:34:11 2025).\n",
      "Using the latest cached version of the dataset since argilla/10Kprompts-mini couldn't be found on the Hugging Face Hub\n",
      "Using the latest cached version of the dataset since argilla/10Kprompts-mini couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\alix\\.cache\\huggingface\\datasets\\argilla___10_kprompts-mini\\default\\0.0.0\\cf99b34e5949c3e2310321438fb201cf27647d01 (last modified on Fri Jun 13 18:34:11 2025).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'instruction': 'How can I create an efficient and robust workflow that utilizes advanced automation techniques to extract targeted data, including customer information, from diverse PDF documents and effortlessly integrate it into a designated Google Sheet? Furthermore, I am interested in establishing a comprehensive and seamless system that promptly activates an SMS notification on my mobile device whenever a new PDF document is uploaded to the Google Sheet, ensuring real-time updates and enhanced accessibility.',\n",
       "   'topic': 'Software Development'}],\n",
       " True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset = LoadDataFromHub(\n",
    "        repo_id= \"argilla/10Kprompts-mini\",\n",
    "        num_examples=1,\n",
    "        pipeline=Pipeline(name=\"showcase-pipeline\"),\n",
    "    )\n",
    "load_dataset.load()\n",
    "next(load_dataset.process())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16884b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating with meta-llama/Meta-Llama-3-8B-Instruct ---\n",
      "[{'instruction': 'Which are the top 5 cities to visit in Spain and why?', 'generation': \"Spain is a country with a rich history, vibrant culture, and stunning landscapes, offering countless options for travelers. Here are the top 5 cities to visit in Spain, in no particular order, along with some reasons why:\\n\\n1. **Madrid**:\\n\\t* The capital city is a must-visit, with world-class museums like the Prado, Reina Sofia, and Thyssen-Bornemisza.\\n\\t* Enjoy the city's lively nightlife, with many bars, restaurants, and clubs.\\n\\t* Explore the historic center, including the Royal Palace, Plaza Mayor, and Puerta del Sol.\\n\\t* Visit the famous Retiro Park, a beautiful green oasis in the heart of the city.\\n2. **Barcelona**:\\n\\t* Discover the works of Antoni Gaudí, including the iconic Sagrada Família, Park Güell, and Casa Batlló.\\n\\t* Stroll along La Rambla, a famous pedestrian street lined with street performers, cafes, and shops.\\n\\t* Visit the Gothic Quarter, with its narrow streets, historic buildings, and lively atmosphere.\\n\\t* Enjoy the city's beaches, such as Barceloneta and Nova Icària.\\n3. **Seville**:\\n\\t* Explore the charming Santa Cruz neighborhood, with its narrow streets, flower-filled patios, and historic buildings.\\n\\t* Visit the magnificent Cathedral of Seville, the third-largest Gothic church in the world.\\n\\t* Discover the Royal Alcázar of Seville, a palace and gardens complex that's a UNESCO World Heritage Site.\\n\\t* Enjoy the city's vibrant flamenco music and dance scene.\\n4. **Granada**:\\n\\t* Marvel at the breathtaking Alhambra, a medieval Islamic palace and one of the most impressive architectural achievements in the world.\\n\\t* Explore the narrow streets of the Albaicín neighborhood, with its stunning views of the Alhambra and the city.\\n\\t* Visit the Granada Cathedral, a beautiful example of Gothic and Renaissance architecture.\\n\\t* Experience the city's rich Moorish heritage and cultural traditions.\\n5. **Valencia**:\\n\\t* Discover the stunning City of Arts and Sciences, a complex of futuristic buildings and parks.\\n\\t* Visit the Central Market, a beautiful example of Art Nouveau architecture and a great place to try local cuisine.\\n\\t* Explore the historic center, including the Silk Exchange and the Town Hall.\\n\\t* Enjoy the city's beautiful beaches, such as Playa de la Malvarrosa\", 'distilabel_metadata': {'raw_output_generate_for_meta-llama_Meta-Llama-3-8B-Instruct': \"Spain is a country with a rich history, vibrant culture, and stunning landscapes, offering countless options for travelers. Here are the top 5 cities to visit in Spain, in no particular order, along with some reasons why:\\n\\n1. **Madrid**:\\n\\t* The capital city is a must-visit, with world-class museums like the Prado, Reina Sofia, and Thyssen-Bornemisza.\\n\\t* Enjoy the city's lively nightlife, with many bars, restaurants, and clubs.\\n\\t* Explore the historic center, including the Royal Palace, Plaza Mayor, and Puerta del Sol.\\n\\t* Visit the famous Retiro Park, a beautiful green oasis in the heart of the city.\\n2. **Barcelona**:\\n\\t* Discover the works of Antoni Gaudí, including the iconic Sagrada Família, Park Güell, and Casa Batlló.\\n\\t* Stroll along La Rambla, a famous pedestrian street lined with street performers, cafes, and shops.\\n\\t* Visit the Gothic Quarter, with its narrow streets, historic buildings, and lively atmosphere.\\n\\t* Enjoy the city's beaches, such as Barceloneta and Nova Icària.\\n3. **Seville**:\\n\\t* Explore the charming Santa Cruz neighborhood, with its narrow streets, flower-filled patios, and historic buildings.\\n\\t* Visit the magnificent Cathedral of Seville, the third-largest Gothic church in the world.\\n\\t* Discover the Royal Alcázar of Seville, a palace and gardens complex that's a UNESCO World Heritage Site.\\n\\t* Enjoy the city's vibrant flamenco music and dance scene.\\n4. **Granada**:\\n\\t* Marvel at the breathtaking Alhambra, a medieval Islamic palace and one of the most impressive architectural achievements in the world.\\n\\t* Explore the narrow streets of the Albaicín neighborhood, with its stunning views of the Alhambra and the city.\\n\\t* Visit the Granada Cathedral, a beautiful example of Gothic and Renaissance architecture.\\n\\t* Experience the city's rich Moorish heritage and cultural traditions.\\n5. **Valencia**:\\n\\t* Discover the stunning City of Arts and Sciences, a complex of futuristic buildings and parks.\\n\\t* Visit the Central Market, a beautiful example of Art Nouveau architecture and a great place to try local cuisine.\\n\\t* Explore the historic center, including the Silk Exchange and the Town Hall.\\n\\t* Enjoy the city's beautiful beaches, such as Playa de la Malvarrosa\", 'raw_input_generate_for_meta-llama_Meta-Llama-3-8B-Instruct': [{'role': 'user', 'content': 'Which are the top 5 cities to visit in Spain and why?'}], 'statistics_generate_for_meta-llama_Meta-Llama-3-8B-Instruct': {'input_tokens': 19, 'output_tokens': 513}}, 'model_name': 'meta-llama/Meta-Llama-3-8B-Instruct'}]\n",
      "\n",
      "\n",
      "--- Generating with mistralai/Mixtral-8x7B-Instruct-v0.1 ---\n",
      "[{'instruction': 'Which are the top 5 cities to visit in Spain and why?', 'generation': ' 1. Madrid: As the capital of Spain, Madrid is a must-visit city. It is home to some of the country\\'s most famous museums, including the Prado Museum, which houses an extensive collection of European art, and the Reina Sofia Museum, where you can see Picasso\\'s \"Guernica.\" The city also has a vibrant nightlife, with many bars and clubs, and is known for its delicious cuisine, especially its tapas.\\n\\n2. Barcelona: Barcelona is famous for its unique architecture, much of which was designed by the famous architect Antoni Gaudí. The Sagrada Familia, Park Güell, and Casa Batlló are just a few of the many examples of his work that can be found in the city. Barcelona is also located on the Mediterranean Sea, so there are many beautiful beaches to visit.\\n\\n3. Seville: Seville is the capital of the Andalusia region in southern Spain and is known for its flamenco dancing, which is a traditional Spanish art form. The city is also home to the stunning Alcázar palace, which was built for the Christian king Peter of Castile in the 14th century. The palace is a mix of Christian and Moorish architecture and is a UNESCO World Heritage site.\\n\\n4. Valencia: Valencia is a coastal city located on the eastern coast of Spain. It is known for its City of Arts and Sciences, a complex of cultural and educational buildings designed by Santiago Calatrava. The city is also home to the beautiful Turia Gardens, which were built on the former riverbed of the Turia River.\\n\\n5. Granada: Granada is located at the foot of the Sierra Nevada mountains in southern Spain. It is home to the stunning Alhambra, a palace and fortress complex that was built during the Nasrid Dynasty in the 13th and 14th centuries. The Alhambra is a UNESCO World Heritage site and is one of the most visited attractions in Spain.', 'distilabel_metadata': {'raw_output_generate_for_mistralai_Mixtral-8x7B-Instruct-v0_1': ' 1. Madrid: As the capital of Spain, Madrid is a must-visit city. It is home to some of the country\\'s most famous museums, including the Prado Museum, which houses an extensive collection of European art, and the Reina Sofia Museum, where you can see Picasso\\'s \"Guernica.\" The city also has a vibrant nightlife, with many bars and clubs, and is known for its delicious cuisine, especially its tapas.\\n\\n2. Barcelona: Barcelona is famous for its unique architecture, much of which was designed by the famous architect Antoni Gaudí. The Sagrada Familia, Park Güell, and Casa Batlló are just a few of the many examples of his work that can be found in the city. Barcelona is also located on the Mediterranean Sea, so there are many beautiful beaches to visit.\\n\\n3. Seville: Seville is the capital of the Andalusia region in southern Spain and is known for its flamenco dancing, which is a traditional Spanish art form. The city is also home to the stunning Alcázar palace, which was built for the Christian king Peter of Castile in the 14th century. The palace is a mix of Christian and Moorish architecture and is a UNESCO World Heritage site.\\n\\n4. Valencia: Valencia is a coastal city located on the eastern coast of Spain. It is known for its City of Arts and Sciences, a complex of cultural and educational buildings designed by Santiago Calatrava. The city is also home to the beautiful Turia Gardens, which were built on the former riverbed of the Turia River.\\n\\n5. Granada: Granada is located at the foot of the Sierra Nevada mountains in southern Spain. It is home to the stunning Alhambra, a palace and fortress complex that was built during the Nasrid Dynasty in the 13th and 14th centuries. The Alhambra is a UNESCO World Heritage site and is one of the most visited attractions in Spain.', 'raw_input_generate_for_mistralai_Mixtral-8x7B-Instruct-v0_1': [{'role': 'user', 'content': 'Which are the top 5 cities to visit in Spain and why?'}], 'statistics_generate_for_mistralai_Mixtral-8x7B-Instruct-v0_1': {'input_tokens': 22, 'output_tokens': 443}}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in .env file or environment variables.\")\n",
    "\n",
    "class PatchedInferenceEndpointsLLM(InferenceEndpointsLLM):\n",
    "    def load(self) -> None:\n",
    "        AsyncLLM.load(self)\n",
    "        self._aclient = AsyncInferenceClient(\n",
    "            model=self.model_id,\n",
    "            token=self.api_key.get_secret_value() if self.api_key else None\n",
    "        )\n",
    "\n",
    "with Pipeline(name=\"showcase-pipeline\") as pipeline:\n",
    "    models_to_run = [\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "    ]\n",
    "\n",
    "    for model in models_to_run:\n",
    "        safe_model_name = model.replace('/', '_').replace('.', '_')\n",
    "\n",
    "        task = TextGeneration(\n",
    "            name=f\"generate_for_{safe_model_name}\", # Use the safe name\n",
    "            llm=PatchedInferenceEndpointsLLM(\n",
    "                model_id=model,\n",
    "                generation_kwargs={\"max_new_tokens\": 512, \"temperature\": 0.7, \"do_sample\": True},\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        task.load()\n",
    "        print(f\"--- Generating with {model} ---\")\n",
    "        result = next(task.process([{\"instruction\": \"Which are the top 5 cities to visit in Spain and why?\"}]))\n",
    "        print(result)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dda7291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generations': ['Madrid', 'Barcelona'],\n",
       "  'model_names': ['meta-llama/Meta-Llama-3-8B-Instruct',\n",
       "   'mistralai/Mixtral-8x7B-Instruct-v0.1']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_responses = GroupColumns(\n",
    "    columns=[\"generation\", \"model_name\"],\n",
    "    output_columns=[\"generations\", \"model_names\"],\n",
    "    pipeline=Pipeline(name=\"showcase-pipeline\"),\n",
    ")\n",
    "next(\n",
    "    group_responses.process(\n",
    "        [\n",
    "            {\n",
    "                \"generation\": \"Madrid\",\n",
    "                \"model_name\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "            },\n",
    "        ],\n",
    "        [\n",
    "            {\n",
    "                \"generation\": \"Barcelona\",\n",
    "                \"model_name\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a90a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'instruction': \"What's the capital of Spain?\", 'generations': ['Madrid', 'Barcelona'], 'ratings': [5, 1], 'rationales': ['The text provides accurate and helpful information, correctly stating the capital of Spain as Madrid. It is confident and free of hallucinations, perfectly aligning with the instruction.', 'The text provides inaccurate information, stating Barcelona as the capital of Spain, which is incorrect. It does not align with the instruction and contains a severe hallucination.'], 'distilabel_metadata': {'raw_output_evaluate_capital_of_spain_q': '#### Output for Text 1\\nRating: 5 (Excellent)\\nRationale: The text provides accurate and helpful information, correctly stating the capital of Spain as Madrid. It is confident and free of hallucinations, perfectly aligning with the instruction.\\n\\n#### Output for Text 2\\nRating: 1 (Low Quality)\\nRationale: The text provides inaccurate information, stating Barcelona as the capital of Spain, which is incorrect. It does not align with the instruction and contains a severe hallucination.', 'raw_input_evaluate_capital_of_spain_q': [{'role': 'system', 'content': 'Your role is to evaluate text quality based on given criteria.\\nYou\\'ll receive an instructional description (\"Instruction\") and 2 text outputs (\"Text\").\\nUnderstand and interpret instructions to evaluate effectively.\\nProvide annotations for each text with a rating and rationale.\\nThe 2 texts given are independent, and should be evaluated separately.\\n'}, {'role': 'user', 'content': \"# General Text Quality Assessment\\n\\nEvaluate the model's outputs based on various criteria:\\n\\n1. **Correctness & Informativeness**: Does the output provide accurate and helpful information?\\n2. **Honesty & Uncertainty**: How confidently does the model convey its information, and does it express uncertainty appropriately?\\n3. **Truthfulness & Hallucination**: Does the model introduce misleading or fabricated details?\\n4. **Instruction Following**: Does the model's output align with given instructions and the user's intent?\\n\\nYour role is to provide a holistic assessment considering all the above factors.\\n\\n**Scoring**: Rate outputs 1 to 5 based on the overall quality, considering all aspects:\\n1. **Low Quality**: Contains inaccuracies, may be entirely wrong or has severe hallucinations.\\n2. **Moderate Quality**: Addresses some aspects, but has errors or is partially aligned with instructions.\\n3. **Good**: Generally accurate but may contain minor errors or slight deviations.\\n4. **Very Good**: Near perfect, with minor issues in terms of alignment or confidence.\\n5, **Excellent**: Accurate, confident, aligned with instructions, and free of hallucinations.\\n\\n## Format:\\n\\n### Input\\nInstruction: [Clearly specify the task goal and restrictions]\\n\\nTexts:\\n<text 1> [Text 1]\\n<text 2> [Text 2]\\n\\n### Output\\n#### Output for Text 1\\nRating: [Rating for text 1]\\nRationale: [Rationale for the rating in short sentences]\\n\\n#### Output for Text 2\\nRating: [Rating]\\nRationale: [Rationale]\\n\\n---\\n\\n## Annotation\\n\\n### Input\\nInstruction: What's the capital of Spain?\\n\\nTexts:\\n<text 1> Madrid\\n<text 2> Barcelona\\n\\n### Output\\n\"}], 'statistics_evaluate_capital_of_spain_q': {'input_tokens': 429, 'output_tokens': 100}}, 'model_name': 'meta-llama/Meta-Llama-3-70B-Instruct'}]\n"
     ]
    }
   ],
   "source": [
    "# Use the Pipeline context manager for creating and running the step\n",
    "with Pipeline(name=\"showcase-evaluation-pipeline\") as pipeline:\n",
    "    # Create the UltraFeedback step inside the context\n",
    "    evaluate_responses = UltraFeedback(\n",
    "        name=\"evaluate_capital_of_spain_q\", \n",
    "        aspect=\"overall-rating\",\n",
    "        llm=PatchedInferenceEndpointsLLM( \n",
    "            model_id=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "            generation_kwargs={\"max_new_tokens\": 512, \"temperature\": 0.0}, # Temp 0.0 for consistent ratings\n",
    "        ),\n",
    "        # The `pipeline` argument is not needed when creating inside a `with` block\n",
    "    )\n",
    "\n",
    "    evaluate_responses.load()\n",
    "\n",
    "    # Process a sample input\n",
    "    result = next(\n",
    "        evaluate_responses.process(\n",
    "            [\n",
    "                {\n",
    "                    \"instruction\": \"What's the capital of Spain?\",\n",
    "                    \"generations\": [\"Madrid\", \"Barcelona\"],\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6296c1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': \"What's the capital of Spain?\",\n",
       "  'generations': ['Madrid', 'Barcelona'],\n",
       "  'generation_models': ['Meta-Llama-3-8B-Instruct',\n",
       "   'Mixtral-8x7B-Instruct-v0.1'],\n",
       "  'ratings': [5, 1],\n",
       "  'prompt': \"What's the capital of Spain?\",\n",
       "  'prompt_id': '26174c953df26b3049484e4721102dca6b25d2de9e3aa22aa84f25ed1c798512',\n",
       "  'chosen': [{'role': 'user', 'content': \"What's the capital of Spain?\"},\n",
       "   {'role': 'assistant', 'content': 'Madrid'}],\n",
       "  'chosen_model': 'Meta-Llama-3-8B-Instruct',\n",
       "  'chosen_rating': 5,\n",
       "  'rejected': [{'role': 'user', 'content': \"What's the capital of Spain?\"},\n",
       "   {'role': 'assistant', 'content': 'Barcelona'}],\n",
       "  'rejected_model': 'Mixtral-8x7B-Instruct-v0.1',\n",
       "  'rejected_rating': 1}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_dpo = FormatTextGenerationDPO(pipeline=Pipeline(name=\"showcase-pipeline\"))\n",
    "format_dpo.load()\n",
    "next(\n",
    "    format_dpo.process(\n",
    "        [\n",
    "            {\n",
    "                \"instruction\": \"What's the capital of Spain?\",\n",
    "                \"generations\": [\"Madrid\", \"Barcelona\"],\n",
    "                \"generation_models\": [\n",
    "                    \"Meta-Llama-3-8B-Instruct\",\n",
    "                    \"Mixtral-8x7B-Instruct-v0.1\",\n",
    "                ],\n",
    "                \"ratings\": [5, 1],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c77a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps import PreferenceToArgilla\n",
    "load_dotenv()\n",
    "\n",
    "argilla_api = os.getenv(\"Argilla_API\")\n",
    "# Create the step inside the Pipeline context manager\n",
    "with Pipeline(name=\"showcase-pipeline\") as pipeline:\n",
    "    to_argilla = PreferenceToArgilla(\n",
    "        dataset_name=\"preference-dataset\",\n",
    "        dataset_workspace=\"argilla\",\n",
    "        # Replace with your actual Argilla URL and API key\n",
    "        api_url=\"https://huggingface.co/spaces/AlexVal/my-argilla.hf.space\",\n",
    "        api_key=argilla_api,\n",
    "        num_generations=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps import (\n",
    "    LoadDataFromHub,\n",
    "    GroupColumns,\n",
    "    FormatTextGenerationDPO,\n",
    "    PreferenceToArgilla,\n",
    ")\n",
    "from distilabel.steps.tasks import TextGeneration, UltraFeedback\n",
    "\n",
    "# Import the necessary classes for our patch\n",
    "from distilabel.models import InferenceEndpointsLLM, AsyncLLM\n",
    "from huggingface_hub import AsyncInferenceClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "argilla_api = os.getenv(\"ARGILLA_API_KEY\")\n",
    "if not hf_token or not argilla_api:\n",
    "    raise ValueError(\"HF_TOKEN or ARGILLA_API_KEY not found in environment.\")\n",
    "\n",
    "\n",
    "with Pipeline(name=\"generate-dataset\") as pipeline:\n",
    "    load_dataset = LoadDataFromHub(\n",
    "        name=\"load_prompts\",\n",
    "        repo_id=\"argilla/10Kprompts-mini\",\n",
    "        num_examples=1\n",
    "    )\n",
    "\n",
    "\n",
    "    generate_llama = TextGeneration(\n",
    "        name=\"generate_llama\",\n",
    "        llm=PatchedInferenceEndpointsLLM(\n",
    "            model_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "            generation_kwargs={\"max_new_tokens\": 512, \"temperature\": 0.7, \"do_sample\": True},\n",
    "        )\n",
    "    )\n",
    "    generate_mixtral = TextGeneration(\n",
    "        name=\"generate_mixtral\",\n",
    "        llm=PatchedInferenceEndpointsLLM(\n",
    "            model_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "            generation_kwargs={\"max_new_tokens\": 512, \"temperature\": 0.7, \"do_sample\": True},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    group_responses = GroupColumns(\n",
    "        name=\"group_generations\",\n",
    "        columns=[\"generation\", \"model_name\"],\n",
    "        output_columns=[\"generations\", \"model_names\"],\n",
    "    )\n",
    "\n",
    "\n",
    "    evaluate_responses = UltraFeedback(\n",
    "        name=\"evaluate_with_llama_70b\",\n",
    "        aspect=\"overall-rating\",\n",
    "        llm=PatchedInferenceEndpointsLLM(\n",
    "            model_id=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "            generation_kwargs={\"max_new_tokens\": 512, \"temperature\": 0.0},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    format_dpo = FormatTextGenerationDPO(name=\"format_for_dpo\")\n",
    "\n",
    "\n",
    "    to_argilla = PreferenceToArgilla(\n",
    "        name=\"upload_to_argilla\",\n",
    "        dataset_name=\"preference-dataset\",\n",
    "        dataset_workspace=\"argilla\",\n",
    "        api_url=\"https://AlexVal-my-argilla.hf.space\", \n",
    "        api_key=\"EPyMl_vB6pv3jF0rklhw8bbl8GCtykcSq9Sc4AgWklWsHri7SohXeb4p-ogcw5oLCJ4q1UstT-XfAZrCrj-5Mhvy0dvKYIxihoSwPaGbbbg\",\n",
    "        num_generations=2\n",
    "    )\n",
    "\n",
    "\n",
    "    load_dataset.connect(generate_llama)\n",
    "    load_dataset.connect(generate_mixtral)\n",
    "\n",
    "    generate_llama.connect(group_responses)\n",
    "    generate_mixtral.connect(group_responses)\n",
    "\n",
    "    group_responses.connect(evaluate_responses)\n",
    "    evaluate_responses.connect(format_dpo)\n",
    "    format_dpo.connect(to_argilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/16/25 19:35:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> 📝 Pipeline data will be written to               <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1015\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1015</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'C:\\Users\\alix\\.cache\\distilabel\\pipelines\\generate-dataset\\af989d7b808a3</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">82c497d9972f914d45c0f744a65\\executions\\2f57935956ef442a7b64aa17a33ab69ecb</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">736109\\data\\steps_outputs'</span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/16/25 19:35:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m 📝 Pipeline data will be written to               \u001b]8;id=314756;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=373083;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1015\u001b\\\u001b[2m1015\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'C:\\Users\\alix\\.cache\\distilabel\\pipelines\\generate-dataset\\af989d7b808a3\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m82c497d9972f914d45c0f744a65\\executions\\2f57935956ef442a7b64aa17a33ab69ecb\u001b[0m \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m736109\\data\\steps_outputs'\u001b[0m                                                \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> ⌛ The steps of the pipeline will be loaded in    <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1046\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         stages:                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * Legend: 🚰 GeneratorStep 🌐 GlobalStep 🔄 Step                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * Stage <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🚰 <span style=\"color: #008000; text-decoration-color: #008000\">'load_prompts'</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🔄 <span style=\"color: #008000; text-decoration-color: #008000\">'generate_llama'</span>                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🔄 <span style=\"color: #008000; text-decoration-color: #008000\">'generate_mixtral'</span>                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🔄 <span style=\"color: #008000; text-decoration-color: #008000\">'group_generations'</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🔄 <span style=\"color: #008000; text-decoration-color: #008000\">'evaluate_with_llama_70b'</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🔄 <span style=\"color: #008000; text-decoration-color: #008000\">'format_for_dpo'</span>                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>            - 🔄 <span style=\"color: #008000; text-decoration-color: #008000\">'upload_to_argilla'</span>                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m ⌛ The steps of the pipeline will be loaded in    \u001b]8;id=252085;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=541547;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1046\u001b\\\u001b[2m1046\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         stages:                                                                   \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * Legend: 🚰 GeneratorStep 🌐 GlobalStep 🔄 Step                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * Stage \u001b[1;36m0\u001b[0m:                                                               \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🚰 \u001b[32m'load_prompts'\u001b[0m                                                    \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🔄 \u001b[32m'generate_llama'\u001b[0m                                                  \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🔄 \u001b[32m'generate_mixtral'\u001b[0m                                                \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🔄 \u001b[32m'group_generations'\u001b[0m                                               \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🔄 \u001b[32m'evaluate_with_llama_70b'\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🔄 \u001b[32m'format_for_dpo'\u001b[0m                                                  \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m            - 🔄 \u001b[32m'upload_to_argilla'\u001b[0m                                               \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> ⏳ Waiting for all the steps of stage <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> to        <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1382\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1382</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         load<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m ⏳ Waiting for all the steps of stage \u001b[1;36m0\u001b[0m to        \u001b]8;id=910813;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=500827;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1382\u001b\\\u001b[2m1382\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         load\u001b[33m...\u001b[0m                                                                   \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/16/25 19:35:14] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'root'</span><span style=\"font-weight: bold\">]</span> Argilla: Logged in as AlexVal with the role Role.owner         <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\argilla\\_api\\_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\argilla\\_api\\_client.py#157\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/16/25 19:35:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'root'\u001b[0m\u001b[1m]\u001b[0m Argilla: Logged in as AlexVal with the role Role.owner         \u001b]8;id=900639;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\argilla\\_api\\_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=605429;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\argilla\\_api\\_client.py#157\u001b\\\u001b[2m157\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> ⏳ Steps from stage <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> loaded: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                 <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1418\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1418</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'load_prompts'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'generate_llama'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'generate_mixtral'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'group_generations'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'evaluate_with_llama_70b'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'format_for_dpo'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'upload_to_argilla'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m ⏳ Steps from stage \u001b[1;36m0\u001b[0m loaded: \u001b[1;36m2\u001b[0m/\u001b[1;36m7\u001b[0m                 \u001b]8;id=449006;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=21550;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1418\u001b\\\u001b[2m1418\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'load_prompts'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                           \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'generate_llama'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'generate_mixtral'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                       \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'group_generations'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                      \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'evaluate_with_llama_70b'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'format_for_dpo'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'upload_to_argilla'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                      \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/16/25 19:35:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> ⏳ Steps from stage <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> loaded: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                 <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1418\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1418</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'load_prompts'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'generate_llama'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'generate_mixtral'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'group_generations'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'evaluate_with_llama_70b'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'format_for_dpo'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'upload_to_argilla'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/16/25 19:35:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m ⏳ Steps from stage \u001b[1;36m0\u001b[0m loaded: \u001b[1;36m3\u001b[0m/\u001b[1;36m7\u001b[0m                 \u001b]8;id=667202;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=346088;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1418\u001b\\\u001b[2m1418\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'load_prompts'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                           \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'generate_llama'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'generate_mixtral'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                       \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'group_generations'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                      \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'evaluate_with_llama_70b'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'format_for_dpo'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'upload_to_argilla'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                      \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[06/16/25 19:35:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'distilabel.pipeline'</span><span style=\"font-weight: bold\">]</span> ⏳ Steps from stage <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> loaded: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>                 <a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1418\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1418</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'load_prompts'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'generate_llama'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'generate_mixtral'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'group_generations'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'evaluate_with_llama_70b'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'format_for_dpo'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>          * <span style=\"color: #008000; text-decoration-color: #008000\">'upload_to_argilla'</span> replicas: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[06/16/25 19:35:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m[\u001b[0m\u001b[32m'distilabel.pipeline'\u001b[0m\u001b[1m]\u001b[0m ⏳ Steps from stage \u001b[1;36m0\u001b[0m loaded: \u001b[1;36m4\u001b[0m/\u001b[1;36m7\u001b[0m                 \u001b]8;id=68142;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py\u001b\\\u001b[2mbase.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=921362;file://c:\\ProgramData\\anaconda3\\envs\\llmops-env\\Lib\\site-packages\\distilabel\\pipeline\\base.py#1418\u001b\\\u001b[2m1418\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'load_prompts'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                           \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'generate_llama'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'generate_mixtral'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                       \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'group_generations'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                      \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'evaluate_with_llama_70b'\u001b[0m replicas: \u001b[1;36m0\u001b[0m/\u001b[1;36m1\u001b[0m                                \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'format_for_dpo'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                         \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m          * \u001b[32m'upload_to_argilla'\u001b[0m replicas: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m                                      \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This should now run without errors. It takes a long time though.\n",
    "distiset = pipeline.run()\n",
    "print(distiset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
